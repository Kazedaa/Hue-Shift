{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models.vae import VAE\n",
    "from models.lpips import LPIPS\n",
    "from models.discriminator import PatchGANDiscriminator\n",
    "from utils.dataset import Dataset\n",
    "from utils.train_vae import train\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CONFIG = \"configs/vae.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the config file #\n",
    "with open(CONFIG, 'r') as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "model_config = config['model_config']\n",
    "dataset_config = config['dataset_config']\n",
    "training_config = config['training_config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(model_config = model_config).to(DEVICE)\n",
    "lpips_model = LPIPS().eval().to(DEVICE) # frozen\n",
    "discriminator = PatchGANDiscriminator().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((dataset_config['IMG_SIZE'], dataset_config['IMG_SIZE']), Image.BICUBIC),\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    Dataset(dataset_config['ROOT'],transform),\n",
    "    batch_size= dataset_config['BATCH_SIZE'],\n",
    "    shuffle = True,\n",
    "    num_workers = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_criterion = torch.nn.MSELoss()\n",
    "adv_criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_d = Adam(discriminator.parameters(), lr = 1E-5, betas=(0.5, 0.999))\n",
    "optimizer_g = Adam(model.parameters(), lr=1E-5, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    model = model,\n",
    "    discriminator = discriminator,\n",
    "    lpips_model = lpips_model,\n",
    "    num_epochs = training_config['NUM_EPOCHS'],\n",
    "    data_loader = data_loader,\n",
    "    optimizer_g = optimizer_g,\n",
    "    optimizer_d = optimizer_d,\n",
    "    recon_criterion = recon_criterion,\n",
    "    adv_criterion = adv_criterion,\n",
    "    adv_start = training_config['ADV_START'],\n",
    "    sample_step = training_config['SAMPLE_STEP']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hueshift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
